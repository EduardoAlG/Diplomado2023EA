{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be9c68c",
   "metadata": {},
   "source": [
    "# Assignment 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0674e63c",
   "metadata": {},
   "source": [
    "### Instalamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c8959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain openai pypdf python-dotenv chromadb  tiktoken -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass, openai, os\n",
    "api_key = \"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\"\n",
    "openai.apikey = api_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be66f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb27a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a56ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94037286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47024912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ee310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e1854",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embedding = embeddings[0]\n",
    "print(\"length: \", len(text_embedding), \"\\nvector_sample: \" ,text_embedding[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50292d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass, openai, os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA as RQa\n",
    "\n",
    "api_key = \"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\"\n",
    "openai.apikey = api_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "\n",
    "url_pdf = input(\"Insert the pdfurl: \")\n",
    "\n",
    "loader = PyPDFLoader(url_pdf)\n",
    "pages = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "splits = text_splitter.split_documents(pages)\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# persist_directory = './thesis_chroma/'\n",
    "\n",
    "# !rm -rf ./thesis_chroma  # remove old database files if any (linux, Mac)\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    # persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "\n",
    "llm_model = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(model_name = llm_model, temperature = 0)\n",
    "\n",
    "# example url: https://tesis.pucp.edu.pe/repositorio/bitstream/handle/20.500.12404/9279/VERA_ARELA_EDITH_IMPACTO_DE_LA_MINERIA.pdf?sequence=1&isAllowed=y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88077a4",
   "metadata": {},
   "source": [
    "#### Preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8898d59",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (560220765.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    Retrieval-based Question Answering\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA as RQa\n",
    "\n",
    "Retrieval-based Question Answering\n",
    "\n",
    "llm_model = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(model_name=llm_model, temperature=0)\n",
    "question = \"What are some of the challenges hindering the widespread adoption and reuse of innovations in document image analysis (DIA), particularly in comparison to disciplines like natural language processing and computer vision?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be28395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué mecanismos y/o procesos implementa el programa Mibeca para la inserción laboral de los egresados?\n",
    "# ¿Cómo se evalúa la calidad de los servicios prestados por los IEST elegibles por el programa Mibeca para el desarrollo de competencias en los becarios?\n",
    "while True:\n",
    "    question = input(\"Ask: \")\n",
    "    if question == \"\":\n",
    "        break\n",
    "    stuff = RQa.from_chain_type(\n",
    "        llm, retriever = vectordb.as_retriever(),\n",
    "        chain_type = \"stuff\" # default\n",
    "    )\n",
    "    stuff_result = stuff({\"query\": question})\n",
    "    result = stuff_result['result']\n",
    "    format_response = f\"\"\"\n",
    "    Question:\n",
    "      {question}\n",
    "    Result:\n",
    "      {result}\n",
    "    ------------ x -------------\n",
    "    \"\"\"\n",
    "    print(format_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
