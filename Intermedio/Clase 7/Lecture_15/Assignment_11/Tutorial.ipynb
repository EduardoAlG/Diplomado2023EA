{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain openai pypdf python-dotenv chromadb  tiktoken -q"
      ],
      "metadata": {
        "id": "Gf_R6kIjyDaP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install openai\n",
        "import getpass, openai, os\n",
        "api_key = \"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\"\n",
        "openai.apikey = api_key\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key"
      ],
      "metadata": {
        "id": "_tPbGnX6yKE6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader"
      ],
      "metadata": {
        "id": "CX1PSzOoyhvH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z30r5W5I7pha",
        "outputId": "71fd9026-2254-424c-b3af-46a93c66f47e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jq in /usr/local/lib/python3.10/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n"
      ],
      "metadata": {
        "id": "9Fhm1Sp0ym09"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "15EDzI6CynZT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import MarkdownHeaderTextSplitter"
      ],
      "metadata": {
        "id": "DHMLSIPZyq_6"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import (\n",
        "    Language,\n",
        "    RecursiveCharacterTextSplitter,\n",
        ")"
      ],
      "metadata": {
        "id": "hPl2rVS0ytGb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "embedding = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "6pS-pxmwyvF_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_embedding = embeddings[0]\n",
        "print(\"length: \", len(text_embedding), \"\\nvector_sample: \" ,text_embedding[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNdfPrxbyv1L",
        "outputId": "91838141-adb9-47e4-9378-04384bd60a9d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length:  1536 \n",
            "vector_sample:  [-0.020291369630971504, -0.00707277412171542, -0.022869059830264393]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXTuhZybTR74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c0c051f-8e0e-4ebf-fcd7-240013ba17d5"
      },
      "source": [
        "import getpass, openai, os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA as RQa\n",
        "\n",
        "api_key = \"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\"\n",
        "openai.apikey = api_key\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "\n",
        "url_pdf = input(\"Insert the pdfurl: \")\n",
        "\n",
        "loader = PyPDFLoader(url_pdf)\n",
        "pages = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")\n",
        "splits = text_splitter.split_documents(pages)\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "# persist_directory = './thesis_chroma/'\n",
        "\n",
        "# !rm -rf ./thesis_chroma  # remove old database files if any (linux, Mac)\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    # persist_directory=persist_directory\n",
        ")\n",
        "\n",
        "\n",
        "llm_model = \"gpt-3.5-turbo\"\n",
        "llm = ChatOpenAI(model_name = llm_model, temperature = 0)\n",
        "\n",
        "# example url: https://tesis.pucp.edu.pe/repositorio/bitstream/handle/20.500.12404/27040/HUAMAN%c3%8d_LLAMOCCA_ROGER_ANGEL_DESARROLLO_COMPETENCIAS.pdf?sequence=1&isAllowed=y\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Insert the pdfurl: https://tesis.pucp.edu.pe/repositorio/bitstream/handle/20.500.12404/27040/HUAMAN%c3%8d_LLAMOCCA_ROGER_ANGEL_DESARROLLO_COMPETENCIAS.pdf?sequence=1&isAllowed=y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3AqDHDxztSj",
        "outputId": "7c65dbed-786d-4d9c-e9ae-86a793a0b9fd"
      },
      "source": [
        "import getpass, openai, os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA as RQa\n",
        "\n",
        "api_key = \"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\"\n",
        "openai.apikey = api_key\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "\n",
        "url_pdf = input(\"Insert the pdfurl: \")\n",
        "\n",
        "loader = PyPDFLoader(url_pdf)\n",
        "pages = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")\n",
        "splits = text_splitter.split_documents(pages)\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "# persist_directory = './thesis_chroma/'\n",
        "\n",
        "# !rm -rf ./thesis_chroma  # remove old database files if any (linux, Mac)\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    # persist_directory=persist_directory\n",
        ")\n",
        "\n",
        "\n",
        "llm_model = \"gpt-3.5-turbo\"\n",
        "llm = ChatOpenAI(model_name = llm_model, temperature = 0)\n",
        "\n",
        "# example url: https://tesis.pucp.edu.pe/repositorio/bitstream/handle/20.500.12404/27040/HUAMAN%c3%8d_LLAMOCCA_ROGER_ANGEL_DESARROLLO_COMPETENCIAS.pdf?sequence=1&isAllowed=y\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Insert the pdfurl: https://tesis.pucp.edu.pe/repositorio/bitstream/handle/20.500.12404/27040/HUAMAN%c3%8d_LLAMOCCA_ROGER_ANGEL_DESARROLLO_COMPETENCIAS.pdf?sequence=1&isAllowed=y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ask"
      ],
      "metadata": {
        "id": "DK9ZVLbYztSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA as RQa\n",
        "\n",
        "Retrieval-based Question Answering\n",
        "\n",
        "llm_model = \"gpt-3.5-turbo\"\n",
        "llm = ChatOpenAI(model_name=llm_model, temperature=0)\n",
        "question = \"What are some of the challenges hindering the widespread adoption and reuse of innovations in document image analysis (DIA), particularly in comparison to disciplines like natural language processing and computer vision?\"\n"
      ],
      "metadata": {
        "id": "OEXKB1dX-IJX"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ¿Qué mecanismos y/o procesos implementa el programa Mibeca para la inserción laboral de los egresados?\n",
        "# ¿Cómo se evalúa la calidad de los servicios prestados por los IEST elegibles por el programa Mibeca para el desarrollo de competencias en los becarios?\n",
        "while True:\n",
        "    question = input(\"Ask: \")\n",
        "    if question == \"\":\n",
        "        break\n",
        "    stuff = RQa.from_chain_type(\n",
        "        llm, retriever = vectordb.as_retriever(),\n",
        "        chain_type = \"stuff\" # default\n",
        "    )\n",
        "    stuff_result = stuff({\"query\": question})\n",
        "    result = stuff_result['result']\n",
        "    format_response = f\"\"\"\n",
        "    Question:\n",
        "      {question}\n",
        "    Result:\n",
        "      {result}\n",
        "    ------------ x -------------\n",
        "    \"\"\"\n",
        "    print(format_response)"
      ],
      "metadata": {
        "id": "q9K9ADNqztSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3fHgQKGUd5xK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}